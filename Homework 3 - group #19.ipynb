{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functions\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import enchant \n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_data=pd.read_csv(\"Airbnb_Texas_Rentals.csv\",usecols=['average_rate_per_night', 'bedrooms_count', 'city',\n",
    "       'date_of_listing', 'description', 'latitude', 'longitude', 'title','url'],parse_dates=['date_of_listing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "airbnb_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values of the dataset\n",
    "airbnb_data.isnull().sum()\n",
    "#average_rate_per_night -> replace NAN with 0, convert to int\n",
    "#bedrooms_count -> There are only 3 records so we decided to replace NAN with a category based on the desciption if it's possible. \n",
    "#description, latitude, longitude, title -> replace NAN to 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_data=functions.clean(airbnb_data)\n",
    "airbnb_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#method is run only once at the beginning to make separate .tsv files\n",
    "functions.create_tsv_documents(airbnb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "1) Removing stop words\n",
    "\n",
    "2) Removing punctuation\n",
    "\n",
    "3) Stemming\n",
    "\n",
    "##### remove non english words and words Giulia chooses (room, price, airbnb) MOST often ones_?\n",
    "##### should we remove numbers__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1) Conjunctive query\n",
    "\n",
    "## 3.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(airbnb_data):\n",
    "    #set for vocabulary (values of the set will be the keys fo vocabulary_dict)\n",
    "    vocabulary_lst=[]\n",
    "    #building a dictionary which will be used for making an inverted index\n",
    "    doc_vocabs=defaultdict(list)\n",
    "\n",
    "    for i in airbnb_data.index:\n",
    "        #take one file\n",
    "        df=pd.read_csv('data/doc_'+str(i)+'.tsv',sep='\\t',usecols=['description','title'],encoding='ISO-8859-1')\n",
    "        #preprocessing \n",
    "        df=df.description[0]+' '+df.title[0]\n",
    "        filtered_words=preprocessing_text(df)\n",
    "        temp_vocabulary_set=set()\n",
    "        for word in filtered_words:\n",
    "            temp_vocabulary_set.add(word)\n",
    "        vocabulary_lst.append(temp_vocabulary_set)\n",
    "        doc_vocabs[i]=list(temp_vocabulary_set)\n",
    "    vocabulary_set=set.union(*vocabulary_lst)\n",
    "    #mapping words into integers\n",
    "    vocabulary={}\n",
    "    for k,v in enumerate(vocabulary_set):\n",
    "        vocabulary[v]= k\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a vocabulary\n",
    "vocabulary=functions.build_vocabulary(airbnb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary_set) #11717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.save_vocabulary(vocabulary,'vocabulary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute an inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute an inverted index\n",
    "inverted_idx=functions.compute_inverted_idx(doc_vocabs,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.save_inverted_idx(inverted_idx)\n",
    "inverted_index=functions.load_inverted_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for example number of documents containing word whose id is 11010\n",
    "len(inverted_index[11010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in vocabulary.keys():\n",
    "    if vocabulary[k]==11010:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can clean our vocab more for 2nd part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.search_engine(vocabulary,inverted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for future usage it can be just imported \n",
    "vocabulary=pd.read_csv('vocabulary.csv',encoding='ISO-8859-1')\n",
    "vocabulary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
