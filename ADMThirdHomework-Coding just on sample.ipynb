{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_data=pd.read_csv(\"Airbnb_Texas_Rentals.csv\",usecols=['average_rate_per_night', 'bedrooms_count', 'city',\n",
    "       'date_of_listing', 'description', 'latitude', 'longitude', 'title','url'],parse_dates=['date_of_listing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['average_rate_per_night', 'bedrooms_count', 'city', 'date_of_listing',\n",
       "       'description', 'latitude', 'longitude', 'title', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rate_per_night</th>\n",
       "      <th>bedrooms_count</th>\n",
       "      <th>city</th>\n",
       "      <th>date_of_listing</th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>Humble</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Welcome to stay in private room with queen bed...</td>\n",
       "      <td>30.0201</td>\n",
       "      <td>-95.294</td>\n",
       "      <td>2 Private rooms/bathroom 10min from IAH airport</td>\n",
       "      <td>https://www.airbnb.com/rooms/18520444?location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_rate_per_night bedrooms_count    city date_of_listing  \\\n",
       "0                      27              2  Humble      2016-05-01   \n",
       "\n",
       "                                         description latitude longitude  \\\n",
       "0  Welcome to stay in private room with queen bed...  30.0201   -95.294   \n",
       "\n",
       "                                             title  \\\n",
       "0  2 Private rooms/bathroom 10min from IAH airport   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.airbnb.com/rooms/18520444?location...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18259, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_rate_per_night    28\n",
       "bedrooms_count             3\n",
       "city                       0\n",
       "date_of_listing            0\n",
       "description                2\n",
       "latitude                  34\n",
       "longitude                 34\n",
       "title                      3\n",
       "url                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check null values of the dataset\n",
    "airbnb_data.isnull().sum()\n",
    "#average_rate_per_night -> replace NAN with 0, convert to int\n",
    "#bedrooms_count -> There are only 3 records so we decided to replace NAN with a category based on the desciption if it's possible. \n",
    "#description, latitude, longitude, title -> replace NAN to 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_rate_per_night            object\n",
       "bedrooms_count                    object\n",
       "city                              object\n",
       "date_of_listing           datetime64[ns]\n",
       "description                       object\n",
       "latitude                         float64\n",
       "longitude                        float64\n",
       "title                             object\n",
       "url                               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(airbnb_data):\n",
    "    \"\"\"\n",
    "    Method that removes nan values and imputes them\n",
    "    \n",
    "    Input: dataframe\n",
    "    Output: cleaned dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    #replace NAN with 0\n",
    "    airbnb_data.average_rate_per_night.replace(np.nan, '$0',inplace=True)\n",
    "    #convert to int and remove $\n",
    "    airbnb_data.average_rate_per_night=airbnb_data.average_rate_per_night.replace('[\\$]', '', regex=True).astype(int)\n",
    "\n",
    "    #replace NAN with'unknown'\n",
    "\n",
    "    airbnb_data.description.replace(np.nan,'unknown',inplace=True)\n",
    "    airbnb_data.title.replace(np.nan,'unknown',inplace=True)\n",
    "\n",
    "    airbnb_data.latitude.replace(np.nan,'unknown',inplace=True)\n",
    "    airbnb_data.longitude.replace(np.nan,'unknown',inplace=True)\n",
    "\n",
    "    #check where bedrooms_count doesn't have a value and save indexes of those records to a list\n",
    "    null_value_idx=airbnb_data[airbnb_data.bedrooms_count.isnull()].index\n",
    "    #if the word studio is mentioned in description then it is a studio otherwise 'unknown'\n",
    "    for idx in null_value_idx:\n",
    "        if 'studio' in airbnb_data.iloc[idx].description.split():\n",
    "            airbnb_data.bedrooms_count[idx]='Studio'\n",
    "        else:\n",
    "            airbnb_data.bedrooms_count[idx]='unknown'\n",
    "        \n",
    "    return airbnb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dusica\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Dusica\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "average_rate_per_night    0\n",
       "bedrooms_count            0\n",
       "city                      0\n",
       "date_of_listing           0\n",
       "description               0\n",
       "latitude                  0\n",
       "longitude                 0\n",
       "title                     0\n",
       "url                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_data=clean(airbnb_data)\n",
    "airbnb_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18259, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tsv_documents(airbnb_data):\n",
    "    \"\"\"\n",
    "    Method that creates different .tsv files for each record in the airbnb_data \n",
    "    \n",
    "    Input: dataframe\n",
    "    \"\"\"   \n",
    "    #clean data\n",
    "    airbnb_data=clean(airbnb_data)\n",
    "    \n",
    "    #for each index make a dataframe of airbnb_data and store it into new tsv file\n",
    "    for i in airbnb_data.index:\n",
    "        pd.DataFrame(airbnb_data.loc[i]).transpose().to_csv('data/doc_'+str(i)+'.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#method is run only once at the beginning to make separate .tsv files\n",
    "create_tsv_documents(airbnb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "1) Removing stop words\n",
    "\n",
    "2) Removing punctuation\n",
    "\n",
    "3) Stemming\n",
    "\n",
    "##### remove non english words and words Giulia chooses (room, price, airbnb) MOST often ones_?\n",
    "##### should we remove numbers__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1) Conjunctive query\n",
    "\n",
    "## 3.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a vocabulary\n",
    "\n",
    "#set for vocabulary (values of the set will be the keys fo vocabulary_dict)\n",
    "vocabulary_set=set()\n",
    "#building a dictionary which will be used for making an inverted index\n",
    "vocabulary_dict=defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(df):\n",
    "    #remove upper cases\n",
    "    df=df.lower()\n",
    "    #replacing new line sign '\\n' with a whitespace ' '    \n",
    "    df=df.replace('\\\\n',' ')\n",
    "\n",
    "    #removing stop words and punctuation\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "    #for removing punctuations\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    #to tokenize the string\n",
    "    word_tokens = tokenizer.tokenize(df) \n",
    "\n",
    "    #stemming\n",
    "    ps = PorterStemmer()\n",
    "    filtered_words = [ps.stem(w) for w in word_tokens if not w in stop_words] \n",
    "\n",
    "    #remove non-english words\n",
    "    \n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a vocabulary\n",
    "\n",
    "#set for vocabulary (values of the set will be the keys fo vocabulary_dict)\n",
    "vocabulary_set=set()\n",
    "#building a dictionary which will be used for making an inverted index\n",
    "doc_vocabs=defaultdict(list)\n",
    "\n",
    "for i in range((airbnb_data.shape[0])//8900):\n",
    "    #take one file\n",
    "    df=pd.read_csv('data/doc_'+str(i)+'.tsv',sep='\\t',usecols=['description','title'],encoding='ISO-8859-1')\n",
    "    #preprocessing \n",
    "    df=df.description[0]+' '+df.title[0]\n",
    "    filtered_words=preprocessing_text(df)\n",
    "    for word in filtered_words:\n",
    "        vocabulary_set.add(word)\n",
    "    doc_vocabs[i]=list(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary={}\n",
    "for k,v in enumerate(vocabulary_set):\n",
    "    vocabulary[v]='id'+str(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_dataframe=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_dataframe['word']=vocabulary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_dataframe.to_csv('vocabulary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute an inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inverted_idx(doc_vocabs,vocabulary):\n",
    "    \"\"\"\n",
    "    method that computes an inverted index\n",
    "    \n",
    "    input: doc_vocabs(dictionary), vocabulary(dictionary of all unique words, key=term, value=term_id)\n",
    "    output: inverted_idx(dictionary, key=term_id, value=list of document_ids) \n",
    "    \"\"\"\n",
    "    #initialize defaultdict for making an inverted index\n",
    "    inverted_idx = defaultdict(list)\n",
    "    #in every document look for every word and assign document id to the words which belong to it\n",
    "    for idx in doc_vocabs.keys():\n",
    "        for word in doc_vocabs[idx]:\n",
    "            inverted_idx[vocabulary[word]].append(idx)\n",
    "    return inverted_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problematico -- saving a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: Since you do not want to compute the inverted \n",
    "#index every time you use the Search Engine, \n",
    "#it is worth to think to store it in a separate file and load it in memory when needed.\n",
    "\n",
    "# Save a dictionary into a pickle file.\n",
    "import pickle\n",
    "\n",
    "pickle.dump(inverted_idx, open(\"save.p\", \"wb\"))  # save it into a file named save.p\n",
    "\n",
    "# Load the dictionary back from the pickle file.\n",
    "\n",
    "inverted_index = pickle.load(open(\"save.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR saving the vocabulary into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_engine():\n",
    "    user_query=str(input())\n",
    "    #input()\n",
    "\n",
    "    user_query=preprocessing_text(user_query)\n",
    "\n",
    "    list_term_idx=[]\n",
    "    result_set=[]\n",
    "    for word in user_query:\n",
    "        if word in vocabulary.keys():\n",
    "            list_term_idx.append(set(inverted_idx[vocabulary[word]]))\n",
    "        else:\n",
    "            list_term_idx.append({'x'})\n",
    "            break\n",
    "    result_set=list(set.intersection(*list_term_idx))\n",
    "    if 'x' in result_set or not result_set:\n",
    "        result_set='No results! Try again!'\n",
    "    print(result_set)\n",
    "    result_set=finalize_output(result_set)\n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "user_query='room'\n",
    "#input()\n",
    "\n",
    "user_query=preprocessing_text(user_query)\n",
    "\n",
    "list_term_idx=[]\n",
    "result_set=[]\n",
    "for word in user_query:\n",
    "    if word in vocabulary.keys():\n",
    "        list_term_idx.append(set(inverted_idx[vocabulary[word]]))\n",
    "    else:\n",
    "        list_term_idx.append('x')\n",
    "        break\n",
    "result_set=list(set.intersection(*list_term_idx))\n",
    "if not (result_set):\n",
    "    result_set='No results! Try again!'\n",
    "print(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "for i,val in enumerate(result_set):\n",
    "    #take one file\n",
    "    df=df.append(pd.read_csv('data/doc_'+str(val)+'.tsv',sep='\\t',usecols=['description','title','city','url'],encoding='ISO-8859-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n",
      "|    |        A |        B |        C |\n",
      "|----+----------+----------+----------|\n",
      "|  0 | 0.703786 | 0.563027 | 0.578585 |\n",
      "|  1 | 0.855807 | 0.795622 | 0.131662 |\n",
      "|  2 | 0.543194 | 0.163419 | 0.313004 |\n",
      "|  3 | 0.138488 | 0.836076 | 0.78933  |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "df = pd.DataFrame(np.random.random((4,3)), columns=['A','B','C'])\n",
    "\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"orgtbl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Humble</td>\n",
       "      <td>Welcome to stay in private room with queen bed...</td>\n",
       "      <td>2 Private rooms/bathroom 10min from IAH airport</td>\n",
       "      <td>https://www.airbnb.com/rooms/18520444?location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Stylish, fully remodeled home in upscale NW  ...</td>\n",
       "      <td>Unique Location! Alamo Heights - Designer Insp...</td>\n",
       "      <td>https://www.airbnb.com/rooms/17481455?location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         city                                        description  \\\n",
       "0      0       Humble  Welcome to stay in private room with queen bed...   \n",
       "1      0  San Antonio  Stylish, fully remodeled home in upscale NW  ...   \n",
       "\n",
       "                                               title  \\\n",
       "0    2 Private rooms/bathroom 10min from IAH airport   \n",
       "1  Unique Location! Alamo Heights - Designer Insp...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.airbnb.com/rooms/18520444?location...  \n",
       "1  https://www.airbnb.com/rooms/17481455?location...  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id30'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d', 'i'}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing method on the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_set=set()\n",
    "\n",
    "filtered_words=airbnb_data.description.apply(preprocessing_text)+airbnb_data.title.apply(preprocessing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_voc(x):\n",
    "    x=set(x)\n",
    "    for word in x:\n",
    "        vocabulary_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we should have 11935 words in our voc_set for all files\n",
    "len(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
